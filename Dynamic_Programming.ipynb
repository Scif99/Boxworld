{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Environments.ipynb\n",
      "X X X X X X X \n",
      "X E . B . E X \n",
      "X . . . . A X \n",
      "X . . . . . X \n",
      "X . . . . . X \n",
      "X E . . . ! X \n",
      "X X X X X X X \n",
      "\n",
      "Reward =  -1  : done =  False  : push =  False\n",
      "X X X X X X X \n",
      "X E . B . A X \n",
      "X . . . . . X \n",
      "X . . . . . X \n",
      "X . . . . . X \n",
      "X E . . . ! X \n",
      "X X X X X X X \n",
      "\n",
      "X X X X X X X \n",
      "X E . . . E X \n",
      "X . . A . . X \n",
      "X B . . . . X \n",
      "X . . . . . X \n",
      "X E . . . ! X \n",
      "X X X X X X X \n",
      "\n",
      "up\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -6. -6. -6. -6. -6.  0.]\n",
      " [ 0. -1. -1. -1. -1. -1.  0.]\n",
      " [ 0. -1. -1. -1. -1. -1.  0.]\n",
      " [ 0.  1. -1. -1. -1. -1.  0.]\n",
      " [ 0. -1. -1. -1. -1. -1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "down\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1. -1. -1. -1. -1.  0.]\n",
      " [ 0.  1. -1. -1. -1. -1.  0.]\n",
      " [ 0. -1. -1. -1. -1. -1.  0.]\n",
      " [ 0. -1. -1. -1. -1. -1.  0.]\n",
      " [ 0. -6. -6. -6. -6. -6.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "left\n",
      "[[  0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.  -6.  -1.  -1.  -1.  -1.   0.]\n",
      " [  0.  -6.  -1.  -1.  -1.  -1.   0.]\n",
      " [  0.  -6. -10.  -1.  -1.  -1.   0.]\n",
      " [  0.  -6.  -1.  -1.  -1.  -1.   0.]\n",
      " [  0.  -6.  -1.  -1.  -1.  -1.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.]]\n",
      "right\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1. -1. -1. -1. -6.  0.]\n",
      " [ 0. -1. -1. -1. -1. -6.  0.]\n",
      " [ 0. -1. -1. -1. -1. -6.  0.]\n",
      " [ 0. -1. -1. -1. -1. -6.  0.]\n",
      " [ 0. -1. -1. -1. -1. -6.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "X X X X X X X X X X \n",
      "X E . . . . . . E X \n",
      "X . . . . . . . . X \n",
      "X . . . . . . . . X \n",
      "X . . . . . . . B X \n",
      "X . . . . . . . . X \n",
      "X . . . . A . . . X \n",
      "X . . . . . . . . X \n",
      "X E . . . . . . ! X \n",
      "X X X X X X X X X X \n",
      "\n",
      "11 -1 False\n",
      "X X X X X X X X X X \n",
      "X E . . . . . . E X \n",
      "X . . . . . . . . X \n",
      "X . . . . . . . . X \n",
      "X . . . . . . . B X \n",
      "X . . . . . . . . X \n",
      "X . . . . . . . . X \n",
      "X . . . . A . . . X \n",
      "X E . . . . . . ! X \n",
      "X X X X X X X X X X \n",
      "\n",
      "bug?\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from Environments import Boxworld_DP\n",
    "from Environments import run_experiments\n",
    "from Environments import run_single_exp\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# First define a namedtuple to hold useful information for actions\n",
    "Action = namedtuple('Action', 'name index delta_i delta_j' )\n",
    "up = Action('up', 0, -1, 0)    \n",
    "down = Action('down', 1, 1, 0)    \n",
    "left = Action('left', 2, 0, -1)    \n",
    "right = Action('right', 3, 0, 1) \n",
    "\n",
    "# Use a dictionary to convert indices to actions using the index as a key\n",
    "# Useful for sampling actions for a given state\n",
    "index_to_actions = {}\n",
    "for action in [up, down, left, right]:\n",
    "    index_to_actions[action.index] = action \n",
    "    \n",
    "# Helpful function to convert action in string format to the action object\n",
    "str_to_actions = {}\n",
    "for action in [up,down,left,right]:\n",
    "    str_to_actions[action.name] = action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Policy():\n",
    "    \n",
    "    def __init__(self,environment,gamma):\n",
    "        self.env = environment\n",
    "        self.size_env= environment.size\n",
    "        self.reward_matrix = environment.reward_matrix\n",
    "        self.transition_matrix = environment.transition_matrix\n",
    "        self.coord_to_index = environment.coord_to_index\n",
    "        self.index_pairs_to_state = environment.index_pairs_to_state\n",
    "        self.size_state_space = environment.size**4\n",
    "        \n",
    "        # Initialize policy to be a random one\n",
    "        self.probability_actions = np.ones((self.size_state_space, 4))*0.25 \n",
    "        \n",
    "        # We initialize the values to 0\n",
    "        self.values = np.zeros( self.size_state_space )   \n",
    "        \n",
    "        # Discount factor\n",
    "        self.gamma = gamma\n",
    "     \n",
    "    # Function which samples an action, given a state\n",
    "    def __call__(self,state):\n",
    "        \n",
    "        # Find the probabilities of actions for the given state\n",
    "        prob_actions = self.probability_actions[state]\n",
    "        \n",
    "        # Randomly sample index from this\n",
    "        index = np.random.choice(np.arange(prob_actions.size))\n",
    "        return index_to_actions[index].name\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    # Function that uses a given policy to evaluate the value functions for each state\n",
    "    def iterative_policy_evaluation(self,n_sweeps):\n",
    "        \n",
    "        # Reset the values\n",
    "        self.values = np.zeros(self.size_state_space)\n",
    "        \n",
    "        # Then use bellman expectation equation to iteratively update values\n",
    "        for n in range(n_sweeps):\n",
    "            \n",
    "            self.values = np.sum(self.probability_actions * (self.reward_matrix + \n",
    "                                 self.gamma* np.dot(self.transition_matrix,self.values)), axis=1 )\n",
    "            \n",
    "    # ** Need to pass env in order to get current coordinates of box (in init would only get starting coords...)        \n",
    "    def display_values(self,env):\n",
    "        \n",
    "        value_matrix = np.zeros( (self.size_env,self.size_env) )\n",
    "        \n",
    "        # Get index of box coordinates\n",
    "        box_index = self.coord_to_index[env.position_box[0],env.position_box[1]]\n",
    "            \n",
    "        for i in range(1, self.size_env-1):\n",
    "                for j in range(1, self.size_env-1):\n",
    "\n",
    "                    agent_index = self.coord_to_index[i,j]\n",
    "                    state = self.index_pairs_to_state[box_index,agent_index]\n",
    "                    value_matrix[i,j] = self.values[state]\n",
    "                        \n",
    "        return value_matrix\n",
    "    \n",
    "    def greedy_improvement(self):\n",
    "        \n",
    "        # Get indices of 'best' actions\n",
    "        argmax_actions = np.argmax(self.reward_matrix + self.gamma * np.dot(self.transition_matrix,self.values), axis=1 )\n",
    "        \n",
    "        #Then update policy for each state\n",
    "        for state in range(self.size_state_space):\n",
    "            \n",
    "            greedy_index = argmax_actions[state]\n",
    "            \n",
    "            #But only update if this transition is possible!\n",
    "            if self.transition_matrix[state][greedy_index].sum()!=0:\n",
    "                \n",
    "                self.probability_actions[state,:] = 0\n",
    "                self.probability_actions[state,greedy_index] = 1\n",
    "                \n",
    "            \n",
    "    \n",
    "    #A function that iteratively evaluates and improves a policy \n",
    "    def policy_iteration(self, n_evaluations):\n",
    "        \n",
    "        self.iterative_policy_evaluation(n_evaluations)\n",
    "        self.greedy_improvement()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Policy():\n",
    "    \n",
    "    def __init__(self,environment,gamma):\n",
    "        self.env = environment\n",
    "        self.size_env= environment.size\n",
    "        self.reward_matrix = environment.reward_matrix\n",
    "        self.transition_matrix = environment.transition_matrix\n",
    "        self.coord_to_index = environment.coord_to_index\n",
    "        self.index_pairs_to_state = environment.index_pairs_to_state\n",
    "        self.size_state_space = environment.size**4\n",
    "        \n",
    "        # Initialize policy to be a random one\n",
    "        self.probability_actions = np.ones((self.size_state_space, 4))*0.25 \n",
    "        \n",
    "        # We initialize the values to 0\n",
    "        self.values = np.zeros( self.size_state_space )   \n",
    "        \n",
    "        # Discount factor\n",
    "        self.gamma = gamma\n",
    "     \n",
    "    # Function which samples an action, given a state\n",
    "    def __call__(self,state):\n",
    "        \n",
    "        # Find the probabilities of actions for the given state\n",
    "        prob_actions = self.probability_actions[state]\n",
    "        \n",
    "        # Randomly sample index from this\n",
    "        index = np.random.choice(np.arange(prob_actions.size))\n",
    "        return index_to_actions[index].name\n",
    "    \n",
    "    \n",
    "    # Function that uses a given policy to evaluate the value functions for each state\n",
    "    def iterative_policy_evaluation(self,n_sweeps):\n",
    "        \n",
    "        # Reset the values\n",
    "        self.values = np.zeros(self.size_state_space)\n",
    "        \n",
    "        # Then use bellman expectation equation to iteratively update values\n",
    "        for n in range(n_sweeps):\n",
    "            \n",
    "            self.values = np.sum(self.probability_actions * (self.reward_matrix + \n",
    "                                 self.gamma* np.dot(self.transition_matrix,self.values)), axis=1 )\n",
    "            \n",
    "    # ** Need to pass env in order to get current coordinates of box (in init would only get starting coords...)        \n",
    "    def display_values(self,env):\n",
    "        \n",
    "        value_matrix = np.zeros( (self.size_env,self.size_env) )\n",
    "        \n",
    "        # Get index of box coordinates\n",
    "        box_index = self.coord_to_index[env.position_box[0],env.position_box[1]]\n",
    "            \n",
    "        for i in range(1, self.size_env-1):\n",
    "                for j in range(1, self.size_env-1):\n",
    "\n",
    "                    agent_index = self.coord_to_index[i,j]\n",
    "                    state = self.index_pairs_to_state[box_index,agent_index]\n",
    "                    value_matrix[i,j] = self.values[state]\n",
    "                        \n",
    "        return value_matrix\n",
    "    \n",
    "    def greedy_improvement(self):\n",
    "        \n",
    "        # Get indices of 'best' actions\n",
    "        argmax_actions = np.argmax(self.reward_matrix + self.gamma * np.dot(self.transition_matrix,self.values), axis=1 )\n",
    "        \n",
    "        #Then update policy for each state\n",
    "        for state in range(self.size_state_space):\n",
    "            \n",
    "            greedy_index = argmax_actions[state]\n",
    "            \n",
    "            #But only update if this transition is possible!\n",
    "            if self.transition_matrix[state][greedy_index].sum()!=0:\n",
    "                \n",
    "                self.probability_actions[state,:] = 0\n",
    "                self.probability_actions[state,greedy_index] = 1\n",
    "                \n",
    "            \n",
    "    \n",
    "    #A function that iteratively evaluates and improves a policy \n",
    "    def policy_iteration(self, n_evaluations):\n",
    "        \n",
    "        self.iterative_policy_evaluation(n_evaluations)\n",
    "        self.greedy_improvement()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X X X X X X X \n",
      "X ! B . . E X \n",
      "X . . . . . X \n",
      "X . . . . . X \n",
      "X . . . . . X \n",
      "X E . A . E X \n",
      "X X X X X X X \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "up\n",
      "[[  0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.  -6.  -6.  -6.  -6.  -6.   0.]\n",
      " [  0.  -1. -10.  -1.  -1.  -1.   0.]\n",
      " [  0.  -1.  -1.  -1.  -1.  -1.   0.]\n",
      " [  0.  -1.  -1.  -1.  -1.  -1.   0.]\n",
      " [  0.  -1.  -1.  -1.  -1.  -1.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.]]\n",
      "down\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -1. -1. -1. -1. -1.  0.]\n",
      " [ 0. -1. -1. -1. -1. -1.  0.]\n",
      " [ 0. -1. -1. -1. -1. -1.  0.]\n",
      " [ 0. -1. -1. -1. -1. -1.  0.]\n",
      " [ 0. -6. -6. -6. -6. -6.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "left\n",
      "[[  0.   0.   0.   0.   0.   0.   0.]\n",
      " [  0.  -6.  -1. -48.  -1.  -1.   0.]\n",
      " [  0.  -6.  -1.  -1.  -1.  -1.   0.]\n",
      " [  0.  -6.  -1.  -1.  -1.  -1.   0.]\n",
      " [  0.  -6.  -1.  -1.  -1.  -1.   0.]\n",
      " [  0.  -6.  -1.  -1.  -1.  -1.   0.]\n",
      " [  0.   0.   0.   0.   0.   0.   0.]]\n",
      "right\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1. -1. -1. -1. -6.  0.]\n",
      " [ 0. -1. -1. -1. -1. -6.  0.]\n",
      " [ 0. -1. -1. -1. -1. -6.  0.]\n",
      " [ 0. -1. -1. -1. -1. -6.  0.]\n",
      " [ 0. -1. -1. -1. -1. -6.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "boxworld = Boxworld_DP(7)\n",
    "boxworld.reset()\n",
    "policy = Policy(boxworld,gamma=0.4)\n",
    "\n",
    "# Apply a single greedy improvement, after 25 sweeps\n",
    "for i in range(25):\n",
    "    values = policy.iterative_policy_evaluation(10)\n",
    "    policy.greedy_improvement()\n",
    "\n",
    "boxworld.display()\n",
    "vals = policy.display_values(boxworld)\n",
    "\n",
    "plt.imshow( (vals - vals.min())/(vals.max() - vals.min()) )\n",
    "plt.show()\n",
    "\n",
    "boxworld.print_reward_matrices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([-269, -258, -3078, -660, -2504, -4507, -483, -129, -1660, -266],\n",
       " -129,\n",
       " -1381.4,\n",
       " 1436.1511201819953)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_experiments(boxworld,policy,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving the Policy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -1162.9\n",
      "Time limit expired!\n",
      "1 -1153.55\n",
      "2 -638.55\n",
      "Time limit expired!\n",
      "3 -1067.15\n",
      "4 -504.55\n",
      "5 -432.25\n",
      "6 -845.8\n",
      "7 -472.2\n",
      "8 -802.45\n",
      "9 -766.25\n",
      "10 -1000.65\n",
      "Time limit expired!\n",
      "11 -851.3\n",
      "12 -899.3\n",
      "13 -970.5\n",
      "14 -1335.95\n",
      "15 -806.9\n",
      "16 -657.95\n",
      "Time limit expired!\n",
      "17 -1052.9\n",
      "Time limit expired!\n",
      "18 -1013.85\n",
      "19 -1014.0\n"
     ]
    }
   ],
   "source": [
    "boxworld = Boxworld_DP(7)\n",
    "# Expect a high gamma to be better, as agent needs to be farsighted in an environment like this\n",
    "gamma = 0.4\n",
    "\n",
    "policy = Policy(boxworld,gamma)\n",
    "\n",
    "# Let's now see how our agent does after repeatedly improving the policy\n",
    "for n_improvements in range(20):\n",
    "    \n",
    "    values = policy.policy_iteration(n_evaluations=20)\n",
    "    \n",
    "    _, max_reward, mean_reward, var_reward = run_experiments(boxworld, policy, number_exp=20)\n",
    "    \n",
    "    print(n_improvements, mean_reward)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time limit expired!\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEGCAYAAABCa2PoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAxeUlEQVR4nO3deZxcdZnv8c/TazpLJ2QnayckrGFNi+CCSNABhxGdQcXBBUQRBsbdUczodeM6qIiADBoFWS4qgsPA9Yoso3jRCzgJgiwCRggQEkgIIXsn6fRz/3jOsao71d3V6ao+VdXf9+t1Xl19zqmup09Xn6d+u7k7IiIig1WXdQAiIlIblFBERKQklFBERKQklFBERKQklFBERKQkGrIOICsTJ070tra2rMMQEakqy5Yte8ndJxU6NmwTSltbG0uXLs06DBGRqmJmz/R2TFVeIiJSEkooIiJSEkooIiJSEjWTUMzsBDN7wsyWm9lns45HRGS4qYmEYmb1wOXAicCBwLvN7MBsoxIRGV5qIqEARwLL3f0pd98B/AQ4OeOYRESGlVpJKNOB5/K+X5ns68bMzjKzpWa2dO3atUMWnIjIcFArCcUK7NttXn53X+Lu7e7ePmlSwXE5IiKyh2plYONKYGbe9zOAVWV7teefh5dfhuZmaGmBpiZoaIitsTH3uK5W8rWISP9qJaH8NzDfzOYAzwOnAv9Ytldbty6SSlMTdHZCb4uUNTTAiBGxNTfvnoDyk48SkIhUuZpIKO7eaWbnAbcD9cBV7v5oWV905EgYPbrvc3btiq2jAzZvjscDSUAjRkQCShOPEpCIVLCaSCgA7v4L4BdZx9FNfX1sxUoT0LZtxSWgxsbupR8lIBmOOjvBbGD/a1IWNZNQhsT118PixfDsszB5Mpx3Hpx4Yul+fpqAmpqKO3+wCailJb5vbNw9+TQ2xj+pSNbcYccO2L49tm3bYNOmeM9v2RLHAMaMgYkTYa+9YNSoqEXQe3hIKaEU6/rr4ayzYOvW+P7FF+GCC+JxKZPKQJQ7ATU15ZKPEpCUU2dnLmFs3x7vz3TburX7e9Qs3ptNTVHtXF8fx7dvh5Ur4emn47y6Ohg/PpJMa2skmebmbH6/YUIJpViLF+eSSaqjAy68MG6os2fDrFlxw61UpU5AZt3/0fMTUEtLrhouTUD5m6onhpf0hr99e5Qo0lJGWtLYubP7B5L898qECf1/WDHLtT+murrif/aJJ+IxxPGJE+Nnjh4dSUbvxZIx7+3TaY1rb2/3Aa2HUlfX+yf5fHvvHcll9mxoa8s9njy59j/BpwknTUR9lYAaGiLp5G9p8klLPOkm1aFnKSO/WqqvUsZQfsDo7Ixktn17Lp7W1u5VZS0ttf+/Oghmtszd2wsdUwmlWLNmwTMF1pWZMgUuvjiOrViR+/rQQ/HGTY0cGT8jP8m0tVV+qWYgBtIJoasr/rm3bIENG+JxV9fuySf95Nkz+aQ3ovxNN4Hy6uravS1j8+Zc4ujs7H5++ndpaiqulDEUGhqirWXMmPg+LTk99xw89VTsq6+PqrIJE1RVNkBKKMW64ILubSgQN7rzzoN9940tnzusXZtLMvmJ5vbbu984p07dPdHUeqmmri73CbUv7nGj2rEjrn1n5+43rvQaNTXtnnyam1XdNhA7d3ZPGmmy2LSp+wckyP0NGxvjxluN17VQVdmuXfFB56WXVFU2QKryGohS9fLq6IifkZ9o0sf5CaulpXD12ezZtVOqKaU02eRvA61uy98aavDzVs9Sxtat3RvA+yplNDTU7gec/uzc2b2qzGzYVpX1VeWlhLIn/vhHWL++/4GNA5WWanommhUr4IUXdi/V9Ew0bW21XaoplbRtp1Di6VnP37PEM3Jk4U4GlXTNd+4s3GOqv1KGSm/FS6vKOjriesOwqSpTG0q1MIuEMHkyvOpV3Y91dEQ9b88qtP/9v3sv1fRMOCrVhLStp79/9kLVbbt2FW7naWraPfEUaucpxeDSQqWMtGoq7Y2XH1vayaG5OW5ylZT8qlV/VWXusQ2zqjIllD1RVxf/wO5x8xiKqpERI2D+/NjyuccbuGeiefhhuOOOwqWa/ESjUk3vzIrraeaeK/W88kr8PQZb3ZbfzTaduifdOjq6/+z8Usa4cZoRISv19ZEwRo3K7du5M94Pzz8/LKrKVOW1J7ZtiyqvdevizdLRkZv6YeTI+CRYCW+QtFTTs51mxYrdSzWFeqCpVFN6harb0obffOnNB3KljPwSj1Sn3qrKJkzoXlVW7FixDKgNpYBBJZSeOjqiqLt+fSSYDRtyN4R0kF8lNfCmpZpCiWb16u6ffqdMKZxopkzpP2nedhtcfnnMKjBlCpx7bnazCohUqnQC2W3bcv97aVXZ+PEVV1WmhFJASRNKT2ld6qZNceNety4+laSfNNPurJVQiumpoyOmr1ixonuyeeaZ+J1SI0b03lbT0hLJ5IIL4uflP2fxYiUVkf5UcK8yJZQCyppQCtm2LVeKWbs2kk1XV9R3p417lVSK6ck9EmOhRLNq1e6lmvXrc5P25Zs6FX7+86GKWqQ2pFVl27blqsoaGqKabOLEGKg5RFVl6uVVCdIG2IkTo2E9HSW+eXMkmHXr4o3inhugV0ntF2YR+8SJ0N7jvVSoVHPbbYV/zgsvwO9/D4ccUlm/n0gl661XWXr/qJCqMpVQKoV7rjdPfikGuo+HqJB61H6ddFIkj940NsKCBZGcFi6Egw+uyT77IkMqv6oM4t7Rc1r/QVaVqcqrgIpLKIV0duYGpKWlmHQcRDruoVJvwr21oXzykzBpEixbBkuX5maCbWqKpNLeHttBB1V0TxeRqtBbVdkBB8CMGXv0I5VQCqiKhNKTe25Cvpdfjgb/zZvjmFmuWq1SxiEU08tr0yb4wx8iuSxdCn/+c/yezc1w6KFRekkTTCW3MYlUi1degWnTIqnsASWUAqoyoRSyc2e0xWzcmOtRlo6UbmzMjdiuFhs2dE8wy5fH/paWSDBpCWb//ZVgRPbEhg2xzEYZEor+I6tdOjp63LgYnOgegxa3bMkNvHzllSjBmEWCGTGickoxPY0dC8ceGxtE7Gn12LJl8J3vxP5Ro+Cww3IlmP32q572JZEapYRSa8xy0z9Mnhz7duzIrTvy0ktRXbZrV24OqnTCw0o0bhwsWhQbRJJ84IFcgvnd72L/6NFw+OG5BLPvvpWbNEVqlBLKcJCuO7LXXjEAMV0aNS3FrF0bJQH3+JSfzi9ViTfkCRPgTW+KDSJBpsll2TK4557Y39oKRxyRSzD77FOZv49IDVFCGY7q6uIT/ejR0VgOUYrZvDnaYtasia7Lu3blJh5saanMUszEiXDCCbFBdADIryK7++7YP3ZsJJc0wcydW5kzFYhUMTXKS2FdXVGCSUsxa9bkpoFIp48ZMaLyb8qrV+cSzNKlubEx48d3TzCzZ1f+7yJSCmVslFdCkeKlizVt2NC9mgxyAy8rvefV88/nksuyZZEoIUo6+Qlm5kwlGKlN6uUlFaG5ObYJE6LKaNeu3OJOaVtMOglmpU3ln5o+PbaTT45kuHJlLsEsXQq33x7nTZ7cPcFMn15Zv4dIBVJCkT1XXx/TOowZEwOlYPep/F96KXdua2tllWDMoiQycya8/e2RYJ55Jld6uf/+3JxkU6fmpolpb49PeCLSTQX9dwcz+yLwIWBtsutz7v6L5Nj5wJnALuAj7n57sn8hcDXQAvwC+KgP17q8rKUT2E2YAPPm5Sawe+GFuFnv2hUJqKUl60h3Zxa94Nra4JRTIsE8/XQuwfz2t7mZkqdP716CSTs3iAxjFZdQEhe7+zfzd5jZgcCpwEHANOAuM9vX3XcBVwBnAfcRCeUEoJfpbmVI1ddHD6uxY6Pr7tq18NRT0XbR1BSllkrtzmsWVXtz58I73xkdFZ56qnsPsltvjXNnzuxegpk4MdPQRbJQqQmlkJOBn7j7duBpM1sOHGlmK4BWd78XwMyuBd6GEkrlaWiIqqK9947uyStXxhLFXV2RWCp9Ovu6uih1zZsHp54acf/5z7kEc+edcPPNce7s2bkEs3BhlNhEalylJpTzzOx9wFLgk+6+HphOlEBSK5N9O5PHPffvxszOIkoyzJo1qwxhS9FaW+HAA+PmvGZNrtTS3BzHqqEBvK4upnzZbz847bSoznvyyVw35V/+En72szh37tzuVWTjxmUaukg5ZJJQzOwuYGqBQ4uJ6quvAJ58vQj4AFDoDuN97N99p/sSYAlEt+EBBy6l19QU02hPnx7dGZ99Nrr21tVFYqmmiS3r66Mr5gEHwHveE8sPPP54JJcHHoj2lxtvjHPnzcuVYI44IqoEi5mdWaSCZZJQ3P34Ys4zs+8D6XqxK4GZeYdnAKuS/TMK7JdqYpab5HLffeOm+tRTMdalpSVG9VdDqSVfQ0MsIrZgAZx+eiSYxx7LVZHdfDP85Cfxe02ZEu1L6UzRL7wQ68mAkopUjYob2Ghme7v76uTxx4FXu/upZnYQ8CPgSKJR/r+A+e6+y8z+G/hn4H6iUf6ytGdYbzSwsQp0dUX34xUrojqsri4STiV1PR6MnTvh0UcjwVx1VUx/01NDQyw81tqa28aMiRJN/r6xY2P/6NGadVn6NswGNn7dzA4jqq1WAB8GcPdHzeynwGNAJ3Bu0sML4Bxy3YZvQw3ytaGuLhqzJ0yIAZQvvBCllp07Y9Dk6NFZRzg4jY0xBf9hh8H3vlf4nM7OKMGsWhXVZxs3xiJrvTGL65KfZPITT88ElP+10gahStWpuITi7u/t49gFwAUF9i8FFpQzLsnYyJHRsD17dky///TTUWppaKi8AZN7YsqU3Dxj+aZOhSVLuu/bsSMSy6ZN8Wkz/drbvtWrc8fSKrVCmpq6J5neEk/P5DR6dPVffykJvQukutTXx5r0kybFgMnnn6/8AZPFOPfcaDPp6MjtGzEi9vfU1BTjXAY61sU9t7pnMduLL0a36I0bo4TYl7RUNJBt7NjBTzCqjgwVRQlFqtfo0dFld599YoqXv/wlSi2NjXGzqtQBk4WkN8Fy3hzT6rDRo3NT5RSrs7P3xJNfItq0KZeM0n19lYoaGgpXzfW1L/16553dk7A6MmSu4hrlh4oa5WtU/oBJ97jxVPqAyVrmHm0+hRJPWiWXbj33bdnS9882y812nW/q1NwUObK7YdYoL7Ln+howOWZMdZVaaoFZtH+NHBk3+oHo7Mwtl1CoZNRbR4YXXxx83LJHlFCkNhUaMLkqGZ40dmx1DZgcrhoacmOTCrnllsIdGSZPLmdU0gd9XJPalg6YPOQQeOMbo5jf0RGllk2bCleZSHU499zC1ZnTpkXXchlySigyfDQ3R7fjN7wBjjwyqsfWrIkG/c7OrKOTgTrxRFi8OKrS0tkGjjsO/vAH+OhH4wODDClVecnwkz9gctu2GKfx9NMxvqMWBkwOJyeeuHuPrp//HL76VTjzTLjkEi2GNoRUQpHhraUlBkwee2xM1tjSEqWWl19WqaVanXQSXHZZ/B1PPx3+9KesIxo2lFBEIDdg8sgj4fWvj1UbN2yIm1JfU51IZXrVq+DKK2NM0oc+BPfck3VEw4ISikhPo0fD/PlRH3/44VFFtmZNTFTZ1yA9qSz77ANXXw1z5sAnP5lbOkDKRglFpDcNDdHg+5rXwGtfG72H1q+Paebzp0iRyjVxYsyF9trXwoUXRptKV1fWUdUsJRSRYqQDJo87LqaT37UrSi0bNugGVelaWuCb34R3vAOuuw7OP18fCMpEvbxEBqKxMQZLTpsWyeS552KCStCAyUpWXw//8i8x2PXb345S5kUXwV57ZR1ZTVEJRWRPpAMmDz5YAyarhRmcdlpUfT3xBJxxRsxULSWjhCIyWPkDJl/96qgeW7tWAyYr1XHHwXe/G/OEfeAD8OCDWUdUM5RQREqlrg7Gj4cjjohxLfPnx01rzZr4KpXj4IOjB9jYsfBP/wR33JF1RDVBCUWkHDRgsvLNmAFXXRWdLT73uUgwqqocFCUUkXLKHzB5zDExYDJdgKq/VRCl/MaNi0XN3vxm+M534GtfU8IfBPXyEhkqo0ZFNdicOdG+kq7V0tgY7S719VlHODw1N8fcX9Onww9/GFPif+1r8feSAVEJRWSo9RwwOX26Bkxmra4upsNfvBjuvz+ma1mzJuuoqo4SikiWWlujy/Fxx8WaLe65aV527Mg6uuHn7W+Hiy+OZaTPOAP+/OesI6oqvVZ5mdnDQK8tVO5+SFkiEhmOGhtjsOTee8eAybVrY1r9V16J4yNGxNT6DaqlLrvXvAZ+8AP42Mfggx+McStHHZV1VFWhr3fnScnXc5Ov1yVfTwPUmihSDumAyXHjor2loyPXiL9mTZRa6uqi19jIkXG+lN6++0Z7ysc+Fot1fe5zcPLJWUdV8XpNKO7+DICZvdbdX5t36LNm9jvgy+UOTmTYGzEitsmTozps8+YowbzwAqxbF/vq6qIBudByuLLnpkyB738/5v76yldiip1zzlES70Mx5edRZvY6d/8tgJm9BlD3B5GhZgZjxsQ2Y0Z0b920Kca2rF6da0Rubo4Eo+qxwRs9OtpU/u3fYszKqlXwhS9ozrZeFPOO+wDwQzMbS7SpbEj2iUiWGhpicsO99oq1P7Zvj+qxtWujBLN9eyShtHqsTn1w9khDQ/T+mj49xqysWQPf+EaMspdu+nyHmVk98AZ3PxQ4BDjM3Q9z9wcG86Jm9g4ze9TMusysvcex881suZk9YWZ/k7d/oZk9nBy71CzKnWbWbGY3JPvvN7O2wcQmUrWam2MQ5YEHxoSVxxwTPcfGjIleY2vWxPgXdU0eOLPo9fXVr8LDD8d69eks0/JXfSYUd98FnJw83ujuG0r0uo8Afw/83/ydZnYgcCpwEHAC8O9JUgO4AjgLmJ9sJyT7zwTWu/s84GLgwhLFKFK9zKLaa9q0mFts0SI4+mjYb784tmZNlGReeQV27sw62upxwglRSnn55UgwjzySdUQVpZgy8O/M7Dtm9nozOyLdBvOi7v4nd3+iwKGTgZ+4+3Z3fxpYDhxpZnsDre5+r7s7cC3wtrznXJM8vglYlJZeRCRRXx89x9raolvsokUxx9i0abBtWy7BbN6sZY77c8QR0Z7S0gIf/jD8+tdZR1QximlDeU3yNb9XlwPHlT4cpgP35X2/Mtm3M3ncc3/6nOcA3L3TzDYAE4CXev5wMzuLKOUwa9asUscuUj2ammJ53IkTY2Dl1q3ReyztnrxrV/feY/qM1l1bW3Qr/sQnYuGuj38c/vEfs44qc/0mFHd/4578YDO7C5ha4NBid7+lt6cVCqGP/X09Z/ed7kuAJQDt7e2aVlQkNXJkbHvvHUsab94c7S4vvBDtLu4x+HLUKPVwSo0fH+uqfP7z8K1vRQ+wj398WM/JVlS/QjP7W6Jd468d3d29z3Eo7n78HsSzEpiZ9/0MYFWyf0aB/fnPWWlmDcBY4OU9eG0RgSiZtLbGNnt2tLFs3BjjXtLR+2a57snD+AbKiBHRpfiSS+BHP4rr89WvRnXYMNRvG4qZfRd4F/DPRGngHcDsMsVzK3Bq0nNrDtH4/nt3Xw1sMrOjkvaR9wG35D3n/cnjU4BfJe0sIlIKjY0wYUKMHn/DG2KNl8MPj30bNuR6j23dOjzXE6mvj6qvT30K7rkn2lXWrcs6qkwU1Ybi7oeY2R/d/UtmdhHwH4N5UTN7O3AZMAn4P2b2oLv/jbs/amY/BR4DOoFzk55mAOcAVwMtwG3JBnAlcJ2ZLSdKJqcOJjYR6UdLS2xTpkT12JYtUWpJR+93dcXYjVGjohQzXJx6alQZLl4cPcAuuSSWKhhGrL8P82Z2v7u/2szuI7r6rgMecff5QxFgubS3t/vSpUuzDkOktqSj99etiwSzeXOUWobT6P3HHou2lB07YgBke3v/zxlKGzZE4jvggD16upktc/eCv1Qx3YZ/bmbjgG8ADwArgB/vUSQiUtvS0fvz5sHrXhfVYwsXRmlm8+Zc9djmzVGSqUUHHhg9wCZOhPPOg1/8IuuIhky/JZRuJ5s1AyNKOMAxMyqhiAwx96geSye3fOmlSCr19bU5ueXGjfDpT8OyZXD22TG6vhK6X5exhNJv+dPM7iFGtN8D/K4WkomIZMAsJlscPTrmxdq1q/Dklk1NcU61V4+1tsY69V/5SnQvXrUqpsGv9t+rD8X8Zu8HXgf8A/ANM9sO3OPuHy9rZCJS29LR++PGwdy5MZnlpk3dJ7eE6p7csrERvvSlSKDf/378Xl//eiTMGlTMwManzGwbsCPZ3gjsWVlJRKQ3zc2xTZwI++/fffT+2rVRPVZXF8mlmkbvm0VX4mnTYozKmWdGD7CphcZ9V7diqrz+Qkxj8iOii+4/u3uNtqaJSEVIJ7dMJ7js6orSy/r1UT2Wjt5vaopzGhuzjrh/f/d30Tnh05+G00+Hb387EmcNKaYMeSnwLPBu4CPA+81sn7JGJSKSr64u1h9pa4tZk487Do48MhYa6+iIEkw1OPJIuPLKqO770Ifgt7/NOqKS6jehuPsl7v4O4HhgGfBF4MkyxyUi0rumphipv99+se5La2t0Ra4G8+bB1VfHtDaf+ATcdFPWEZVMMVOvXGRm9wP3A4cCXyCmRBERyV5dHRx8cLS5VMvU+5MmwZIlsZRAOhdYDYzLKaaX133A1939xXIHIyKyR8aMibnGnnwSJk/OOprijBwJ3/xmbNddF21DX/pSVU9XU0wbys+AN5nZ5wHMbJaZHVnesEREBqitLRJLtVR9QYxJ+cxn4KMfhbvugnPOiXnRqlQxCeVy4GggXT1mU7JPRKRy1NdH1deWLdVVfWQG731vVH09/nhMLPnss1lHtUeKSSivdvdzgQ4Ad18PaIUdEak8Y8fC/PnVOX388cfDFVdE9+gzzoCHHso6ogErJqHsNLN6klUQzWwSUEXpX0SGlTlzon1i69asIxm4Qw+NiSVbW6P66667so5oQIodh3IzMNnMLgB+C/zPskYlIrKnGhrgkEPik341VX2lZs6MpHLAAfDZz8K111bNwmV9JhQzqwOeBv4F+BqwGnibu984BLGJiOyZdH6wl6t0NfBx4+Df/x3e9Ca49NJoX+nszDqqfvXZbdjdu8zsInc/Gnh8iGISERm8efNiMsZt26pzjffmZrjggphq/tpr43f52teiOq9CFVPldYeZ/UOylruISHVIq742bKiaKqPd1NXBRz4SVV/33hvTtVTwNDPFJJRPADcC281so5ltMrONZY5LRGTwxo+PRvpqrfpKnXIKfOtb0Z349NNh+fKsIyqomLm8xrh7nbs3uXtr8n3rUAQnIjJo8+fHbMQdHVlHMjive12sqdLVFVPg339/1hHtpgpXrBERGYDGxuqv+krtv3/0AJs6NarCbr0164i6UUIRkdo3YQLMmlX9VV8QyeTKK6G9Hb785VheuEISpRKKiAwP++4b07NUe9UXxBLCl1wCb30r/OAH8IUvwM6dWUdVXEIxs9eZ2RnJ40lmNqe8YYmIlFhTU8z1VQtVXxC92D7/eTj7bLjtNjjvPNiYbX+pYtZD+R/AZ4Dzk12NwP8qZ1AiImUxeXKs8rh+fdaRlIYZfPCDUfX10EPRWL9qVWbhFFNCeTvwVmALgLuvAsaUMygRkbLZb7+4EW/fnnUkpfOWt8Dll8NLL0W34kcfzSSMYhLKDnd3cpNDjipvSCIiZdTcHFVftVJKSS1cCFddBSNGwFlnwd13D3kIxSSUn5rZ94BxZvYh4C7g+4N5UTN7h5k9amZdZtaet7/NzLaZ2YPJ9t28YwvN7GEzW25ml6Yj982s2cxuSPbfb2Ztg4lNRIaByZNh+vTaSypz5kS34n32gU9/Gn7ykyF9+WIGNn4TuIlYuXE/4AvuftkgX/cR4O+B/1vg2F/c/bBkOztv/xXAWcR69vOBE5L9ZwLr3X0ecDFw4SBjE5FaZxZjOtxhx46soymtCRNivfpjjonlhS+6CHbtGpKXLqqXl7vf6e6fdvdPufudg31Rd/+Tuz9R7PlmtjfQ6u73JtVv1wJvSw6fDFyTPL4JWKR5x0SkXyNGwIIFtTE2pacRI+DrX4d3vxt+/OOYC2wIuksX08trUzKHV/72nJndbGZzyxDTHDP7g5n9xsxen+ybDqzMO2dlsi899hyAu3cCG4AJvfwuZ5nZUjNburaCJ1gTkSEydWpsVbyOe6/q6+GTn4zt7rvhwx+GG2+MJHPQQdDWBtdfX9KX7HP6+sS3gFXAjwADTgWmAk8AVwHHFnqSmd2VnNfTYne/pZfXWg3Mcvd1ZrYQ+E8zOyh53Z7SjuR9Heu+030JsASgvb29Bjqii8igmMGBB8I998TAwMbGrCMqvXe/O6bAP//8KLWkY3CeeSYa7wFOO60kL1VMldcJ7v49d9/k7huTm/Jb3P0GYK/enuTux7v7ggJbb8kEd9/u7uuSx8uAvwD7EiWSGXmnziCSHMmxmQBm1gCMBWqwDCsiZdHSEp/Ya7HqK3XssTBmzO4DOrduhcWLS/YyxSSULjN7p5nVJds7846V9FN+Mgq/Pnk8l2h8f8rdVwObzOyopH3kfUCamG4F3p88PgX4VdLOIiJSnGnToudXLVZ9pXrr0fbssyV7iWISymnAe4E1wIvJ4/eYWQtw3p68qJm93cxWAkcD/8fMbk8OHQP80cweIhrYz3b39GPDOcAPgOVEyeW2ZP+VwAQzW06s3fLZPYlJRIaxtOpr586qWGp3j0yZUnj/rFklewkbrh/m29vbfenSpVmHISKV5Lnn4OGHe7/5VrPbboslhfN7e40cGV2MB9CGYmbL3L290LF+G+XNbAQx1uMgYES6390/UHQEIiLVYPr0mAtr40ZorbF1BE88Mb5edlksIzxrViSYEjXIQ3FVXtcRvbX+BvgN0SC+qWQRiIhUirq6GJuyfXttVn2deGKMS3n0UVixoqTJBIpLKPPc/fPAFne/Bvhb4OCSRiEiUilGjYIDDoB167KOpOoUk1DSVVteMbMFRLfctrJFJCKStZkzYa+9YJMqYwaimISyxMz2Av6V6KL7GJovS0RqWVr1tXXrkM2DVQv6bJQ3szpgo7uvJyZyLMdUKyIilWfMmJhA8oknYoyK9KvPEoq7d7GHY01ERKre7NnR22vz5qwjqQrFVHndaWafMrOZZjY+3coemYhI1urrYzEuVX0VpZjJIdPxJufm7XNU/SUiw0FrK8yfD8uXw6RJWUdT0fpNKO4+ZygCERGpWHPmwOrVsGVLdCuWgopZD2Wkmf2rmS1Jvp9vZieVPzQRkQpRXw+HHBJtKV1dWUdTsYppQ/khsAN4TfL9SuCrZYtIRKQSjR0L8+bV9jT3g1RMQtnH3b9OMsDR3bdReFErEZHaNnduLK+7dWvWkVSkYhLKjmSqegcws32A7WWNSkSkEjU0RNXXpk2q+iqgmITyReCXwEwzux74L+BfyhmUiEjF2muvKKmo6ms3xfTyusPMlgFHEVVdH3X3l8oemYhIpdpnn+j11dERVWACFNfL61bgzcDd7v5zJRMRGfYaG+HQQ2PJ4GG6SGEhxVR5XQS8HnjMzG40s1OSRbdERIav8eNjfIqqvv6q34Ti7r9x938iRsYvAd5JrC8vIjK8zZsXDfX5y+oOY8WUUEh6ef0DcDbwKuCacgYlIlIVmpqi15eqvoDi1pS/AXg10dPrcqItRf3lREQAJk6MWYlXrYIJE7KOJlPFjpTfx93PdvdfAUeb2eVljktEpHrsu29Mz7J9eA/RK6YN5ZfAwWZ2oZmtIKZdebzcgYmIVI2mppjmfv36YV311WuVl5ntC5wKvBtYB9wAmLu/cYhiExGpHpMnw4wZsHZtDH4chvoqoTwOLAL+zt1f5+6XAVphRkSkN/vvHyWUHTuyjiQTfSWUfwBeAH5tZt83s0VoUkgRkd41N+eqvoahXhOKu9/s7u8C9gfuBj4OTDGzK8zszUMUn4hIdZkyBaZOja7Ew0wxjfJb3P16dz8JmAE8CHx2MC9qZt8ws8fN7I9mdrOZjcs7dr6ZLTezJ8zsb/L2LzSzh5Njl5qZJfubzeyGZP/9ZtY2mNhERAbFDA48MGYj3rkz62iGVFEDG1Pu/rK7f8/djxvk694JLHD3Q4AngfMBzOxAoiPAQcAJwL+bWX3ynCuAs4D5yXZCsv9MYL27zwMuBi4cZGwiIoMzYgQcdNCwm5ZlQAmlVNz9DnfvTL69jyj5AJwM/MTdt7v708By4Egz2xtodfd73d2Ba4G35T0nHbl/E7AoLb2IiGRm772j59cwqvrKJKH08AHgtuTxdOC5vGMrk33Tk8c993d7TpKkNgAFh6ua2VlmttTMlq5du7Zkv4CIyG7Sqq/OztiGgbIlFDO7y8weKbCdnHfOYqATuD7dVeBHeR/7+3rO7jvdl7h7u7u3T5o0qfhfRkRkT4wcGVVf69ZlHcmQ6Hcurz3l7sf3ddzM3g+cBCxKqrEgSh4z806bAaxK9s8osD//OSvNrAEYCwyviksRqVzTp8diXBs2wNixWUdTVplUeZnZCcBngLe6+9a8Q7cCpyY9t+YQje+/d/fVwCYzOyppH3kfcEvec96fPD4F+FVeghIRyVZa9bV9e81XfZWthNKP7wDNwJ1J+/l9yeSTj5rZT4HHiKqwc909HZ1/DnA10EK0uaTtLlcC15nZcqJkcuqQ/RYiIsUYNSqSymOPRUN9jcokoSRdfHs7dgFwQYH9S4EFBfZ3AO8oaYAiIqU2c2ZUfW3aBGPGZB1NWVRCLy8RkdpXVwcLFsC2bTVb9aWEIiIyVEaPhgMOqNkBj0ooIiJDadas6O21eXPWkZScEoqIyFCqq4sZibduhV21tSKIEoqIyFAbMyaWDa6xAY9KKCIiWWhri8RSQ1VfSigiIlmor4+qry1bYqr7GqCEIiKSlbFjYf78mqn6UkIREcnSnDkxieTWrf2fW+GUUEREstTQAIccEiPoq7zqSwlFRCRr48bB3LlVP+BRCUVEpBLMmwfNzTE1S5VSQhERqQRp1deGDVClK3AooYiIVIrx46ORvkqrvpRQREQqyfz50NgIHR1ZRzJgSigiIpWksbFqq76UUEREKs2ECTErcZVVfSmhiIhUon33jelZqqjqSwlFRKQSNTXFXF9VVPWlhCIiUqkmT4YZM2D9+qwjKYoSiohIJdtvPzCD7duzjqRfSigiIpWsuTmqvqqglKKEIiJS6SZPhunTKz6pKKGIiFQ6M9h//2ic37Ej62h6pYQiIlINRoyABQsqemyKEoqISLWYOjW2V17JOpKClFBERKqFGRx4IOzaBTt3Zh3NbjJJKGb2DTN73Mz+aGY3m9m4ZH+bmW0zsweT7bt5z1loZg+b2XIzu9TMLNnfbGY3JPvvN7O2LH4nEZEh0dICBx1UkVVfWZVQ7gQWuPshwJPA+XnH/uLuhyXb2Xn7rwDOAuYn2wnJ/jOB9e4+D7gYuLDs0YuIZGnatOj5VWFVX5kkFHe/w907k2/vA2b0db6Z7Q20uvu97u7AtcDbksMnA9ckj28CFqWlFxGRmpRWfe3cCZ2d/Z8/RCqhDeUDwG15388xsz+Y2W/M7PXJvunAyrxzVib70mPPASRJagMwodALmdlZZrbUzJauXbu2lL+DiMjQGjkyqr7Wrcs6kr9qKNcPNrO7gKkFDi1291uScxYDncD1ybHVwCx3X2dmC4H/NLODgEIljnS2tL6Odd/pvgRYAtDe3l4ds62JiPRm+nRYtQo2boTW1qyjKV9Ccffj+zpuZu8HTgIWJdVYuPt2YHvyeJmZ/QXYlyiR5FeLzQBWJY9XAjOBlWbWAIwFKq+1SkSk1OrqYmzKPfdE1VdD2W7pxYWTxYua2QnAZ4C3uvvWvP2TzKw+eTyXaHx/yt1XA5vM7KikfeR9wC3J024F3p88PgX4VZqgRERq3qhRcMABFVH1lVU6+w7QDNyZtJ/fl/ToOgb4spl1AruAs909LW2cA1wNtBBtLmm7y5XAdWa2nCiZnDpUv4SISEWYOTOqvjZtgjFjMgsjk4SSdPEttP9nwM96ObYUWFBgfwfwjpIGKCJSTfKrvkaOjJUeswgjk1cVEZHSGjMmJpDMcMCjEoqISK2YPTsSy+bNmby8EoqISK2or4/FuLZujfm+hpgSiohILWlthfnzM6n6UkIREak1c+ZEd+ItW4b0ZZVQRERqTVr1tXkzdHUN2csqoYiI1KJx42DevCGt+lJCERGpVXPnxtLB27YNycspoYiI1KqGBjjkkJg8cgiqvpRQRERq2V57RUllCKq+lFBERGrdPvtAUxN0dJT1ZZRQRERqXWMjHHpoLBlcxsnYlVBERIaD8eNjfEoZ16FXQhERGS7mzYvuxGWS7fJeIiIydJqa4PDDy9aNWAlFRGQ4GT++bD9aVV4iIlISSigiIlISSigiIlISSigiIlISSigiIlISSigiIlISSigiIlISSigiIlIS5mWcKKySmdla4Jk9fPpE4KUShlMqimtgFNfAVWpsimtgBhPXbHefVOjAsE0og2FmS929Pes4elJcA6O4Bq5SY1NcA1OuuFTlJSIiJaGEIiIiJaGEsmeWZB1ALxTXwCiugavU2BTXwJQlLrWhiIhISaiEIiIiJaGEIiIiJaGE0gczW2FmD5vZg2a2tMBxM7NLzWy5mf3RzI6okLiONbMNyfEHzewLQxTXODO7ycweN7M/mdnRPY5ndb36i2vIr5eZ7Zf3eg+a2UYz+1iPc4b8ehUZV1bvr4+b2aNm9oiZ/djMRvQ4ntX7q7+4srpeH01ierTn3zA5Xvrr5e7aetmAFcDEPo6/BbgNMOAo4P4KietY4OcZXK9rgA8mj5uAcRVyvfqLK5Prlff69cALxICxzK9XEXEN+fUCpgNPAy3J9z8FTs/6ehUZVxbXawHwCDCSWJn3LmB+ua+XSiiDczJwrYf7gHFmtnfWQWXBzFqBY4ArAdx9h7u/0uO0Ib9eRcaVtUXAX9y958wNWb+/eosrKw1Ai5k1EDfKVT2OZ3W9+osrCwcA97n7VnfvBH4DvL3HOSW/XkoofXPgDjNbZmZnFTg+HXgu7/uVyb6s4wI42sweMrPbzOygIYhpLrAW+KGZ/cHMfmBmo3qck8X1KiYuGPrrle9U4McF9mf1/kr1FhcM8fVy9+eBbwLPAquBDe5+R4/Thvx6FRkXDP376xHgGDObYGYjidLIzB7nlPx6KaH07bXufgRwInCumR3T47gVeM5Q9MPuL64HiGqKQ4HLgP8cgpgagCOAK9z9cGAL8Nke52RxvYqJK4vrBYCZNQFvBW4sdLjAviHp599PXEN+vcxsL+IT9RxgGjDKzN7T87QCTy3r9SoyriG/Xu7+J+BC4E7gl8BDQGeP00p+vZRQ+uDuq5Kva4CbgSN7nLKS7ll/BkNQ3O0vLnff6O6bk8e/ABrNbGKZw1oJrHT3+5PvbyJu5D3PGerr1W9cGV2v1InAA+7+YoFjmby/Er3GldH1Oh542t3XuvtO4D+A1/Q4J4vr1W9cWb2/3P1Kdz/C3Y8BXgb+3OOUkl8vJZRemNkoMxuTPgbeTBQj890KvC/pLXEUUdxdnXVcZjbVzCx5fCTxd15Xzrjc/QXgOTPbL9m1CHisx2lDfr2KiSuL65Xn3fRerTTk16uYuDK6Xs8CR5nZyOS1FwF/6nFOFter37iyen+Z2eTk6yzg79n971ny69UwmCfXuCnAzcn7oAH4kbv/0szOBnD37wK/IOomlwNbgTMqJK5TgHPMrBPYBpzqSbeOMvtn4PqkuuQp4IwKuF7FxJXJ9Urqtt8EfDhvX+bXq4i4hvx6ufv9ZnYTUX3UCfwBWJL19Soyrqz+H39mZhOAncC57r6+3NdLU6+IiEhJqMpLRERKQglFRERKQglFRERKQglFRERKQglFRERKQglFhg0z22XdZ9LtOWK+2J9ztpm9r9TxlZKZHWZmbxngc/5fueKR4UHdhmXYMLPN7j66jD+/IZmIL3NmdjrQ7u7nZR2LDB8qociwZ7G+zJfM7AGLdWb2N7O6ZP+4vPOWm9kUM/uimX0q2Xe3mf1PM/sN8FEzW2QxCeXDZnaVmTX39hrJ/i+a2TVmdkdyzt+b2deTc35pZo3JeQvN7DcWE4LebsmssMnrX2hmvzezJ83s9ckAzi8D70pKYu/q8fselJz/oMU6GPOT/ZuTr1/OK8U9b2Y/TPa/J+953zOz+vL+ZaTaKKHIcNLSo8or/0b7UjLh5hXAp9y9C7iFZMpvM3s1sKKXObfGufsbgMuBq4F3ufvBxEwG5/T2Gnn79wH+lphk8H8Bv06evw342ySpXAac4u4LgauAC/Ke3+DuRwIfA/6Hu+8AvgDc4O6HufsNPeI9G7jE3Q8D2ok5nf7K3b+QHHsDMUXId8zsAOBdxMSkhwG7gNMKXAsZxjT1igwn25KbYSH/kXxdRsx7BHADcWP+ITGVe88bM3nnAexHTBT4ZPL9NcC5wLf7eA2A29x9p5k9TCxq9ctk/8NAW/JzFwB3JlPu1BNTpReKva2XGPPdCyw2sxnAf7h7z0kDSeaeuh642N2Xmdl5wELgv5MYWoA1RbyWDCNKKCJhe/J1F7n/i3uBeWY2CXgb8NVenrsl+VpoOvD+XuOv+929y8x25s3z1JWcZ8Cj7t5t6eIifm5B7v4jM7ufKBXdbmYfdPdf9Tjti8QszT9MvjfgGnc/v7+fL8OXqrxEepHc2G8GvgX8yd37myH2caDNzOYl37+XWClvsJ4AJpnZ0QBm1mj9L9K0CRhT6ICZzQWecvdLiRlnD+lx/CRicsiP5O3+L+AUy81gO97MZu/JLyO1SwlFhpOebSj/VsRzbgDeQ+/VXX/l7h3EjK03JtVXXcB3BxVx/NwdxIy1F5rZQ8CD7L4WSE+/Bg4s1ChPtIU8YmYPAvsD1/Y4/klisai0Af7L7v4Y8K/ESqF/JBZuGpbLXUvv1G1YRERKQiUUEREpCSUUEREpCSUUEREpCSUUEREpCSUUEREpCSUUEREpCSUUEREpif8PMnwnU5OVg3sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_environments_per_size=5\n",
    "n_runs_per_environments=5\n",
    "gamma = 0.9\n",
    "\n",
    "mean_reward = []\n",
    "std_reward = []\n",
    "    \n",
    "for size_envir in range(5,10):\n",
    "\n",
    "    # heuristics\n",
    "    n_improvement_steps = size_envir\n",
    "    n_steps_policy_eval = 10\n",
    "    \n",
    "    total_rewards = []\n",
    "\n",
    "    for n_envir in range(n_environments_per_size):\n",
    "\n",
    "        boxworld = Boxworld_DP(size_envir)\n",
    "        policy = Policy(boxworld, gamma)\n",
    "        \n",
    "        for n_improvements in range(n_improvement_steps):\n",
    "    \n",
    "            policy.policy_iteration(n_steps_policy_eval)\n",
    "\n",
    "        all_total_rewards, _, _, _ = run_experiments(boxworld, policy, n_runs_per_environments)\n",
    "\n",
    "        total_rewards += all_total_rewards\n",
    "\n",
    "    mean_reward.append( np.mean(total_rewards) )\n",
    "    std_reward.append( np.std(total_rewards) )\n",
    "\n",
    "mean_reward = np.asarray(mean_reward)\n",
    "std_reward = np.asarray(std_reward)\n",
    "\n",
    "plt.plot(range(5, 10), mean_reward, 'or')\n",
    "plt.plot(range(5, 10), mean_reward, color = 'r')\n",
    "plt.fill_between(range(5, 10), mean_reward - std_reward/2, mean_reward + std_reward/2,\n",
    "             color='r', alpha=0.2)\n",
    "\n",
    "plt.xlabel('Environment size')\n",
    "plt.ylabel('Average reward')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
